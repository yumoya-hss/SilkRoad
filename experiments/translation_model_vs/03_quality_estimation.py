import json
import sys
import os
import torch
import argparse
import gc
import numpy as np
import traceback
import yaml 
from tqdm import tqdm
from PIL import Image, ImageFile
from transformers import CLIPProcessor, CLIPModel, XLMRobertaTokenizer # å¿…é¡»å¯¼å…¥è¿™ä¸ªç”¨äºæ‰‹åŠ¨åŠ è½½åˆ†è¯å™¨

# ==========================================
# ğŸ”¥ å¼ºåˆ¶ç¦»çº¿æ¨¡å¼ (æœ€ä¼˜å…ˆè®¾ç½®) ğŸ”¥
# ==========================================
os.environ["TRANSFORMERS_OFFLINE"] = "1"
os.environ["HF_DATASETS_OFFLINE"] = "1"
os.environ["TOKENIZERS_PARALLELISM"] = "false"

# å»¶è¿Ÿå¯¼å…¥è¯„æµ‹åº“
from bert_score import score as bert_score_func
from comet import download_model, load_from_checkpoint
# å¯¼å…¥ COMET å†…éƒ¨æ¨¡å—ç”¨äºæ‹¦æˆª
from comet.encoders import xlmr 

ImageFile.LOAD_TRUNCATED_IMAGES = True

# ==========================================
# ğŸ”¥ [é…ç½®åŒºåŸŸ] (ç¡¬ç¼–ç è·¯å¾„) ğŸ”¥
# ==========================================

# 1. è¾“å…¥è¾“å‡º
# ä¸Šä¸€æ­¥å›è¯‘(04_b)çš„è¾“å‡ºæ–‡ä»¶
DEFAULT_INPUT_FILE = "dataset_with_bt.json"
# æœ€ç»ˆå¸¦åˆ†æ•°çš„è¾“å‡ºæ–‡ä»¶
DEFAULT_OUTPUT_FILE = "dataset_scored_final.json"

# 2. æ¨¡å‹è·¯å¾„
# COMET-Kiwi (SOTA QEæ¨¡å‹): è‡ªåŠ¨ä¸‹è½½æˆ–æŒ‡å®šæœ¬åœ°è·¯å¾„
# å¦‚æœæœåŠ¡å™¨æœ‰ç½‘ï¼Œç›´æ¥å¡« "Unbabel/wmt22-cometkiwi-da"
# ç¦»çº¿ç¯å¢ƒè¯·æŒ‡å‘æœ¬åœ°è·¯å¾„ (ä»£ç ä¼šè‡ªåŠ¨å¯»æ‰¾ .ckpt)
DEFAULT_COMET_PATH = "models/wmt22-cometkiwi-da" 

# ğŸ”¥ [æ–°å¢] COMET åº•åº§æ¨¡å‹è·¯å¾„ (å¿…é¡»æ‰‹åŠ¨ä¸‹è½½ infoxlm-large) ğŸ”¥
# ç”¨äºé˜²æ­¢ COMET å°è¯•è”ç½‘ä¸‹è½½ microsoft/infoxlm-large
DEFAULT_COMET_ENCODER_PATH = "models/infoxlm-large"

# CLIP æ¨¡å‹ (ç”¨äºè§†è§‰ä¸€è‡´æ€§)
DEFAULT_CLIP_PATH = "models/clip-vit-large-patch14"

# ğŸ”¥ [æ–°å¢] BERTScore æ¨¡å‹ (æœ¬åœ°è·¯å¾„) ğŸ”¥
# æ‚¨ä¸‹è½½çš„æ˜¯ xlm-roberta-largeï¼Œè¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤šè¯­è¨€æ¨¡å‹
DEFAULT_BERT_PATH = "models/xlm-roberta-large"

# å›¾ç‰‡æ ¹ç›®å½• (è·¯å¾„å›é€€ç”¨)
DEFAULT_IMAGE_ROOT = "data/Image50K"

# 3. æ‰¹æ¬¡å¤§å° (æ ¹æ®æ˜¾å­˜ä¼˜åŒ–)
BATCH_SIZE_COMET = 32
BATCH_SIZE_BERT = 64
BATCH_SIZE_CLIP = 64

# GPU ID
DEFAULT_GPU_ID = 0

# ==========================================

def load_data(file_path):
    print(f"ğŸ“– è¯»å–æ•°æ®: {file_path} ...")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            # å…¼å®¹ JSON Array
            if f.read(1) == '[':
                f.seek(0)
                return json.load(f)
            # å…¼å®¹ JSONL
            f.seek(0)
            return [json.loads(line) for line in f if line.strip()]
    except Exception as e:
        print(f"âŒ è¯»å–å¤±è´¥: {e}")
        sys.exit(1)

def save_data(data, path):
    print(f"ğŸ’¾ ä¿å­˜ç»“æœè‡³: {path}")
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

# =========================================================================
# ğŸ”¥ [æ ¸å¿ƒä¿®å¤æ¨¡å—] å†…å­˜çº§æ‹¦æˆª (Double Monkey Patch) ğŸ”¥
# =========================================================================

def ensure_config_exists(encoder_path):
    """
    ç¡®ä¿æœ¬åœ°ç›®å½•ä¸‹æœ‰ config.jsonï¼Œå¦åˆ™åŠ è½½æœ¬åœ°è·¯å¾„ä¹Ÿä¼šæŠ¥é”™ã€‚
    å¦‚æœåªæœ‰ sentencepiece.bpe.model è€Œæ²¡æœ‰ config.jsonï¼Œåˆ™è‡ªåŠ¨ç”Ÿæˆä¸€ä¸ªã€‚
    """
    config_path = os.path.join(encoder_path, "config.json")
    if not os.path.exists(config_path):
        print(f"âš ï¸ è­¦å‘Š: {config_path} ä¸å­˜åœ¨ï¼Œæ­£åœ¨ç”Ÿæˆæ ‡å‡† InfoXLM é…ç½®...")
        # æ ‡å‡† InfoXLM-large é…ç½®
        config_data = {
            "architectures": ["XLMRobertaForMaskedLM"],
            "attention_probs_dropout_prob": 0.1,
            "hidden_size": 1024,
            "intermediate_size": 4096,
            "model_type": "xlm-roberta",
            "num_attention_heads": 16,
            "num_hidden_layers": 24,
            "vocab_size": 250002,
            "sentencepiece_model_file": "sentencepiece.bpe.model",
            "tokenizer_class": "XLMRobertaTokenizer"
        }
        try:
            with open(config_path, 'w') as f:
                json.dump(config_data, f, indent=2)
            print("âœ… config.json ç”Ÿæˆå®Œæ¯•ã€‚")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé…ç½®æ–‡ä»¶å¤±è´¥: {e}")

def apply_monkey_patches(local_encoder_path):
    """
    ğŸ”¥ æ ¸å¿ƒï¼šåŒé‡æ‹¦æˆª (Tokenizer + Encoder) ğŸ”¥
    ç›´æ¥ä¿®æ”¹ COMET æºä»£ç åœ¨å†…å­˜ä¸­çš„è¡Œä¸ºï¼Œå¼ºåˆ¶ä½¿ç”¨æˆ‘ä»¬æŒ‡å®šçš„æœ¬åœ°è·¯å¾„ã€‚
    """
    print(f"ğŸ”§ [Monkey Patch] æ­£åœ¨æ³¨å…¥æ‹¦æˆªé€»è¾‘ (Override transformers loading)...")
    
    # -------------------------------------------
    # 1. Tokenizer æ‹¦æˆª (è§£å†³ OSError: Not found: "None")
    # -------------------------------------------
    vocab_file = os.path.join(local_encoder_path, "sentencepiece.bpe.model")
    if not os.path.exists(vocab_file):
        # å°è¯•é€’å½’æŸ¥æ‰¾
        possible_vocabs = [os.path.join(r, f) for r, d, f in os.walk(local_encoder_path) if f == "sentencepiece.bpe.model"]
        if possible_vocabs:
            vocab_file = possible_vocabs[0]
        else:
            raise FileNotFoundError(f"âŒ è‡´å‘½é”™è¯¯: åœ¨ {local_encoder_path} ä¸­æ‰¾ä¸åˆ° sentencepiece.bpe.model")
    
    print(f"    â³ æ‰‹åŠ¨åŠ è½½ Tokenizer (from {vocab_file})...")
    # æ‰‹åŠ¨åŠ è½½å¥½çš„å¯¹è±¡ (Slow Tokenizer)
    my_tokenizer = XLMRobertaTokenizer(vocab_file=vocab_file)
    
    # æ‹¦æˆª from_pretrainedï¼Œæ°¸è¿œè¿”å›æˆ‘ä»¬æ‰‹åŠ¨åŠ è½½çš„
    def fake_tokenizer_loader(*args, **kwargs):
        print("    ğŸ›¡ï¸  [Tokenizer] æ‹¦æˆªæˆåŠŸï¼Œç›´æ¥è¿”å›é¢„åŠ è½½çš„åˆ†è¯å™¨å¯¹è±¡ã€‚")
        return my_tokenizer
    
    # è¦†ç›–ç±»æ–¹æ³•
    xlmr.XLMRobertaTokenizerFast.from_pretrained = fake_tokenizer_loader

    # -------------------------------------------
    # 2. Encoder æ‹¦æˆª (è§£å†³ MaxRetryError è”ç½‘æŠ¥é”™)
    # -------------------------------------------
    # ä¿å­˜åŸå§‹æ–¹æ³•ï¼Œå› ä¸ºæˆ‘ä»¬éœ€è¦è°ƒç”¨å®ƒï¼Œåªæ˜¯æ”¹ä¸ªå‚æ•°
    original_encoder_loader = xlmr.XLMREncoder.from_pretrained

    def fake_encoder_loader(pretrained_model, load_pretrained_weights=True, local_files_only=False):
        print(f"    ğŸ›¡ï¸  [Encoder] æ‹¦æˆªæ¨¡å‹åŠ è½½è¯·æ±‚: '{pretrained_model}'")
        print(f"    â¡ï¸  å¼ºåˆ¶é‡å®šå‘åˆ°æœ¬åœ°è·¯å¾„: '{local_encoder_path}'")
        
        # å¼ºåˆ¶æŠŠç¬¬ä¸€ä¸ªå‚æ•°(æ¨¡å‹å)æ”¹æˆæˆ‘ä»¬çš„æœ¬åœ°ç»å¯¹è·¯å¾„
        # è¿™æ · transformers å°±ä¼šå»æœ¬åœ°æ‰¾ config.jsonï¼Œè€Œä¸å†è”ç½‘
        return original_encoder_loader(local_encoder_path, load_pretrained_weights, local_files_only=True)

    # è¦†ç›–ç±»æ–¹æ³•
    xlmr.XLMREncoder.from_pretrained = fake_encoder_loader
    
    print("âœ… åŒé‡è¡¥ä¸æ³¨å…¥å®Œæˆï¼COMET ç°åœ¨å°†å®Œå…¨ç¦»çº¿è¿è¡Œã€‚")

# =========================================================================

def run_scoring(data, args):
    device = f"cuda:{args.gpu_id}"
    print(f"ğŸš€ å¼€å§‹è¯„åˆ†æµç¨‹ (Device: {device})...")

    # ------------------------------------------------------
    # 1. BERTScore (Text Consistency: English Source vs BackTrans)
    # ------------------------------------------------------
    print(f"\n[1/3] è®¡ç®— BERTScore (è¯­ä¹‰ä¸€è‡´æ€§)...")
    print(f"      Loading Local BERT: {args.bert_path}")
    
    cands = [] # å€™é€‰: å›è¯‘æ–‡æœ¬
    refs = []  # å‚è€ƒ: åŸå§‹è‹±æ–‡Caption
    map_indices = [] # è®°å½•ç´¢å¼•ä»¥ä¾¿å›å¡«: (data_idx, lang, key)

    # éå†æ•°æ®æ”¶é›† Batch
    for idx, item in enumerate(data):
        if 'translations' not in item: continue
        
        # è‹±æ–‡åŸå¥ (Source)
        short_src = item.get('short_caption_best', '')
        long_src = item.get('long_caption_best', '')

        for lang, trans_obj in item['translations'].items():
            # åŠ¨æ€éå†æ‰€æœ‰é”®å€¼ï¼Œè‡ªåŠ¨é€‚é…ç»´å¾å°”è¯­(åªæœ‰NLLB)å’Œå…¶ä»–è¯­è¨€(åŒæ¨¡å‹)
            for key, val in trans_obj.items():
                # æˆ‘ä»¬åªå…³å¿ƒ 'bt_' å¼€å¤´çš„å›è¯‘å­—æ®µ
                if not key.startswith('bt_'): continue
                
                back_trans = val
                if not back_trans: continue # è·³è¿‡ç©ºå€¼

                # ç¡®å®šå¯¹åº”çš„åŸå¥æ˜¯ Short è¿˜æ˜¯ Long
                # key æ ¼å¼å¦‚: bt_short_nllb, bt_long_seamless
                ref_text = short_src if 'short' in key else long_src
                if not ref_text: continue

                cands.append(back_trans)
                refs.append(ref_text)
                # è®°å½•: åŸå§‹keyå»æ‰ 'bt_' å°±æ˜¯ç¿»è¯‘key, ä¾‹å¦‚ short_nllb
                original_trans_key = key[3:] 
                map_indices.append((idx, lang, original_trans_key))

    # æ‰§è¡Œ BERTScore è®¡ç®—
    if cands:
        try:
            # ğŸ”¥ å…³é”®ä¿®æ”¹: å»æ‰ lang="en"ï¼Œåªä½¿ç”¨ model_type æŒ‡å®šæœ¬åœ°è·¯å¾„
            # xlm-roberta-large ä¹Ÿæ˜¯ 24 å±‚ï¼Œnum_layers=17 æ˜¯ä¸€ä¸ªç»éªŒå€¼
            P, R, F1 = bert_score_func(
                cands, 
                refs, 
                model_type=args.bert_path, # å¼ºåˆ¶ä½¿ç”¨æœ¬åœ°è·¯å¾„
                num_layers=17,             # ä¿æŒé»˜è®¤å±‚æ•°é€‰æ‹©
                verbose=True, 
                device=device, 
                batch_size=args.batch_size_bert
            )
            
            # å›å¡«åˆ†æ•°
            for i, (idx, lang, key) in enumerate(map_indices):
                # å­—æ®µå: score_bert_short_nllb
                score_key = f"score_bert_{key}"
                data[idx]['translations'][lang][score_key] = float(F1[i])
        except Exception as e:
            print(f"âŒ BERTScore è®¡ç®—å‡ºé”™: {e}")
            print("è¯·æ£€æŸ¥ DEFAULT_BERT_PATH æ˜¯å¦æ­£ç¡®æŒ‡å‘äº†åŒ…å« config.json çš„æ–‡ä»¶å¤¹ã€‚")
            traceback.print_exc()
            
    torch.cuda.empty_cache()
    gc.collect()

    # ------------------------------------------------------
    # 2. COMET-Kiwi (Translation Quality: English Source vs Target Translation)
    # ------------------------------------------------------
    print(f"\n[2/3] è®¡ç®— COMET-Kiwi (æ— å‚è€ƒç¿»è¯‘è´¨é‡)...")
    print(f"      Loading Model Dir: {args.comet_path}")
    
    # ğŸ”¥ [åº”ç”¨ä¿®å¤] 1. ç¡®ä¿ config å­˜åœ¨ (é˜²æ­¢æœ¬åœ°åŠ è½½æŠ¥é”™) ğŸ”¥
    ensure_config_exists(args.comet_encoder_path)
    # ğŸ”¥ [åº”ç”¨ä¿®å¤] 2. æ³¨å…¥ Monkey Patch (æ¥ç®¡åŠ è½½è¿‡ç¨‹) ğŸ”¥
    apply_monkey_patches(args.comet_encoder_path)
    
    comet_model = None
    try:
        # ğŸ”¥ ç¬¬ä¸‰æ­¥ï¼šè‡ªåŠ¨å¯»æ‰¾ .ckpt æ–‡ä»¶ ğŸ”¥
        # load_from_checkpoint å¿…é¡»æŒ‡å‘æ–‡ä»¶ï¼Œä¸èƒ½æŒ‡å‘æ–‡ä»¶å¤¹
        ckpt_path = args.comet_path
        if os.path.isdir(ckpt_path):
            print("      (Detecting checkpoint in directory...)")
            # ä¼˜å…ˆæ‰¾ checkpoints/model.ckpt (æ ‡å‡†ç»“æ„)
            possible_ckpt = os.path.join(ckpt_path, "checkpoints", "model.ckpt")
            if os.path.exists(possible_ckpt):
                ckpt_path = possible_ckpt
            else:
                # å¦åˆ™æœç´¢ç›®å½•ä¸‹ä»»ä½• .ckpt æ–‡ä»¶
                found = False
                for root, dirs, files in os.walk(ckpt_path):
                    for f in files:
                        if f.endswith(".ckpt"):
                            ckpt_path = os.path.join(root, f)
                            found = True
                            break
                    if found: break
        
        print(f"      Target Checkpoint File: {ckpt_path}")
        
        # ğŸ”¥ ç¬¬å››æ­¥ï¼šæ ‡å‡†åŠ è½½ ğŸ”¥
        # æ­¤æ—¶æ‰€æœ‰çš„ from_pretrained è°ƒç”¨éƒ½ä¼šè¢«æˆ‘ä»¬çš„ patch æ‹¦æˆªå¹¶é‡å®šå‘
        comet_model = load_from_checkpoint(ckpt_path).to(device).eval()
        print("âœ… COMET æ¨¡å‹åŠ è½½æˆåŠŸï¼")
        
    except Exception as e:
        print(f"âŒ COMET åŠ è½½å¤±è´¥: {e}")
        traceback.print_exc()
        print("æ— æ³•åŠ è½½ COMET æ¨¡å‹ï¼Œè·³è¿‡æ­¤æ­¥éª¤ã€‚")
        comet_model = None

    if comet_model:
        comet_data = [] # [{"src": "...", "mt": "..."}]
        comet_indices = []

        for idx, item in enumerate(data):
            if 'translations' not in item: continue
            
            short_src = item.get('short_caption_best', '')
            long_src = item.get('long_caption_best', '')

            for lang, trans_obj in item['translations'].items():
                for key, val in trans_obj.items():
                    # è·³è¿‡å›è¯‘(bt_)å’Œå·²æœ‰çš„åˆ†æ•°(score_)
                    if key.startswith('bt_') or key.startswith('score_'): continue
                    
                    translation = val
                    if not translation: continue

                    src_text = short_src if 'short' in key else long_src
                    if not src_text: continue

                    # COMET-Kiwi è¾“å…¥: æºè¯­è¨€(è‹±æ–‡) + ç›®æ ‡è¯­è¨€è¯‘æ–‡
                    comet_data.append({"src": src_text, "mt": translation})
                    comet_indices.append((idx, lang, key))

        if comet_data:
            print(f"      Running prediction on {len(comet_data)} samples...")
            try:
                model_output = comet_model.predict(comet_data, batch_size=args.batch_size_comet, gpus=1)
                scores = model_output.scores
                
                for i, (idx, lang, key) in enumerate(comet_indices):
                    score_key = f"score_comet_{key}"
                    data[idx]['translations'][lang][score_key] = float(scores[i])
            except Exception as e:
                print(f"âŒ COMET æ¨ç†å‡ºé”™: {e}")
                traceback.print_exc()

        del comet_model
        torch.cuda.empty_cache()
        gc.collect()

    # ------------------------------------------------------
    # 3. Visual Consistency (CLIP Score: Image vs English BackTrans)
    # ------------------------------------------------------
    print(f"\n[3/3] è®¡ç®— CLIP Score (è§†è§‰ä¸€è‡´æ€§)...")
    print(f"      Loading CLIP: {args.clip_path}")
    
    try:
        clip_model = CLIPModel.from_pretrained(args.clip_path).to(device).eval()
        clip_processor = CLIPProcessor.from_pretrained(args.clip_path)
    except Exception as e:
        print(f"âŒ CLIP åŠ è½½å¤±è´¥: {e}")
        clip_model = None

    if clip_model:
        # CLIP åªèƒ½æŒ‰å›¾å¤„ç†ï¼Œå› ä¸ºæ¯å¼ å›¾å¯¹åº”å¤šä¸ªæ–‡æœ¬
        for idx, item in tqdm(enumerate(data), total=len(data), desc="CLIP Scoring"):
            img_path = item.get('path', '')
            
            # è·¯å¾„æ£€æŸ¥ä¸å›é€€
            if not os.path.exists(img_path):
                filename = os.path.basename(img_path)
                # å°è¯•å»é»˜è®¤å›¾ç‰‡ç›®å½•æ‰¾
                fallback_path = os.path.join(args.image_root, filename)
                if os.path.exists(fallback_path):
                    img_path = fallback_path
                else:
                    continue

            try:
                image = Image.open(img_path).convert("RGB")
            except: continue

            # æ”¶é›†è¿™å¼ å›¾çš„æ‰€æœ‰å›è¯‘æ–‡æœ¬
            texts = []
            keys_map = [] # (lang, original_key)

            if 'translations' not in item: continue
            for lang, trans_obj in item['translations'].items():
                for key, val in trans_obj.items():
                    if key.startswith('bt_') and val:
                        # CLIP æ–‡æœ¬é•¿åº¦é™åˆ¶ 77 tokenï¼Œåšä¸ªæˆªæ–­é˜²æ­¢æŠ¥é”™
                        texts.append(val[:77]) 
                        original_key = key[3:] # å»æ‰ bt_
                        keys_map.append((lang, original_key))
            
            if not texts: continue

            # æ¨ç†
            inputs = clip_processor(text=texts, images=image, return_tensors="pt", padding=True, truncation=True).to(device)
            
            with torch.no_grad():
                outputs = clip_model(**inputs)
                # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                image_embeds = outputs.image_embeds / outputs.image_embeds.norm(dim=-1, keepdim=True)
                text_embeds = outputs.text_embeds / outputs.text_embeds.norm(dim=-1, keepdim=True)
                # [1, embed_dim] @ [embed_dim, num_texts] -> [1, num_texts]
                cosine_scores = (image_embeds @ text_embeds.t()).squeeze(0).cpu().numpy()
                
                if isinstance(cosine_scores, float): cosine_scores = [cosine_scores]

            # å›å¡«
            for i, (lang, original_key) in enumerate(keys_map):
                score_key = f"score_visual_{original_key}"
                item['translations'][lang][score_key] = float(cosine_scores[i])

    return data

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_file", type=str, default=DEFAULT_INPUT_FILE)
    parser.add_argument("--output_file", type=str, default=DEFAULT_OUTPUT_FILE)
    
    # è·¯å¾„å‚æ•°
    parser.add_argument("--comet_path", type=str, default=DEFAULT_COMET_PATH)
    # æ–°å¢ Encoder å‚æ•°
    parser.add_argument("--comet_encoder_path", type=str, default=DEFAULT_COMET_ENCODER_PATH) 
    parser.add_argument("--clip_path", type=str, default=DEFAULT_CLIP_PATH)
    parser.add_argument("--bert_path", type=str, default=DEFAULT_BERT_PATH) # æ–°å¢
    parser.add_argument("--image_root", type=str, default=DEFAULT_IMAGE_ROOT)
    
    # æ˜¾å­˜æ§åˆ¶
    parser.add_argument("--batch_size_comet", type=int, default=BATCH_SIZE_COMET)
    parser.add_argument("--batch_size_bert", type=int, default=BATCH_SIZE_BERT)
    parser.add_argument("--batch_size_clip", type=int, default=BATCH_SIZE_CLIP)
    
    # GPU æ§åˆ¶
    parser.add_argument("--gpu_id", type=int, default=DEFAULT_GPU_ID)
    
    args = parser.parse_args()

    # 1. åŠ è½½
    dataset = load_data(args.input_file)
    
    # 2. è¯„åˆ† (åŒ…å«æ‰€æœ‰é€»è¾‘)
    dataset = run_scoring(dataset, args)
    
    # 3. ä¿å­˜
    save_data(dataset, args.output_file)
