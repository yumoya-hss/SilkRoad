import json
import sys
import os
import torch
import argparse
import gc
from tqdm import tqdm
from transformers import (
    AutoTokenizer, 
    AutoModelForSeq2SeqLM
)

# ==========================================
# 0. ç”¨æˆ·é…ç½®åŒºåŸŸ
# ==========================================

# MADLAD-400 (7B-MT) è·¯å¾„
MADLAD_PATH = "models/madlad400-7b-mt"

# æ‰¹å¤„ç†å¤§å°
BATCH_SIZE = 64 

# ==========================================
# 1. è¯­è¨€æ˜ å°„è¡¨ (ä»…ä¿ç•™ MADLAD æ”¯æŒçš„)
# ==========================================
MADLAD_LANG_MAP = {
    # --- ä¸­äºš ---
    "uyghur": "<2ug>", "uzbek": "<2uz>", "kazakh": "<2kk>", "kyrgyz": "<2ky>", "tajik": "<2tg>",
    # --- å—äºš ---
    "urdu": "<2ur>", "bengali": "<2bn>", "pashto": "<2ps>", "hindi": "<2hi>", 
    "nepali": "<2ne>", "marathi": "<2mr>", "telugu": "<2te>", "tamil": "<2ta>",
    # --- ä¸œå—äºš ---
    "vietnamese": "<2vi>", "thai": "<2th>", "indonesian": "<2id>", "khmer": "<2km>",
    "lao": "<2lo>", "burmese": "<2my>", "malay": "<2ms>",
    # --- ä¸­ä¸œ/è¥¿äºš ---
    "persian": "<2fa>", "arabic": "<2ar>", "turkish": "<2tr>", "hebrew": "<2he>",
    # --- éæ´² ---
    "swahili": "<2sw>", "yoruba": "<2yo>", "zulu": "<2zu>", "amharic": "<2am>", "hausa": "<2ha>",
    # --- ä¸œäºš/å…¶å®ƒ ---
    "mongolian": "<2mn>", "korean": "<2ko>", "japanese": "<2ja>", "chinese": "<2zh>",
}

def load_data(file_path):
    print(f"ğŸ“– è¯»å–æ•°æ®: {file_path} ...")
    data = []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            if f.read(1) == '[':
                f.seek(0); data = json.load(f)
            else:
                f.seek(0); [data.append(json.loads(line)) for line in f if line.strip()]
    except Exception as e:
        print(f"âŒ æ•°æ®é”™è¯¯: {e}"); sys.exit(1)
    return data

# ==========================================
# 2. MADLAD ç¿»è¯‘æ ¸å¿ƒ
# ==========================================
def translate_madlad(model, tokenizer, data, lang_key, device):
    """
    ä¸“é—¨ç”¨äº MADLAD-400 çš„ç¿»è¯‘å‡½æ•°
    """
    madlad_token = MADLAD_LANG_MAP.get(lang_key)
    if not madlad_token:
        print(f"âš ï¸ MADLAD æš‚æœªé…ç½® {lang_key} çš„æ˜ å°„ï¼Œè·³è¿‡ã€‚")
        return [""] * len(data), [""] * len(data)

    print(f"   >> [MADLAD-400] Target: {lang_key} ({madlad_token}) ...")
    
    short_results, long_results = [], []
    
    # å®šä¹‰æ‰¹å¤„ç†ç”Ÿæˆå‡½æ•°
    def run_gen(texts, max_len):
        valid_indices = [i for i, t in enumerate(texts) if t.strip()]
        if not valid_indices: return [""] * len(texts)
        
        # MADLAD éœ€è¦åœ¨è¾“å…¥å‰åŠ  target tokenï¼Œä¾‹å¦‚ "<2zh> I love you"
        inputs_text = [f"{madlad_token} {texts[i]}" for i in valid_indices]

        # ç¼–ç 
        inputs = tokenizer(inputs_text, return_tensors="pt", padding=True, truncation=True, max_length=512).to(device)
        
        # ç”Ÿæˆé…ç½®
        gen_kwargs = {
            "max_new_tokens": max_len,
            "num_beams": 1, # MADLAD é€šå¸¸æ¨è greedy æˆ–å°‘é‡çš„ beams
            "do_sample": False
        }
        
        with torch.inference_mode():
            out = model.generate(**inputs, **gen_kwargs)
        
        decoded = tokenizer.batch_decode(out, skip_special_tokens=True)
        
        final_res = [""] * len(texts)
        for idx, res in zip(valid_indices, decoded):
            final_res[idx] = res.strip()
        return final_res

    # åˆ†æ‰¹å¤„ç†æ•´ä¸ªæ•°æ®é›†
    for i in tqdm(range(0, len(data), BATCH_SIZE), desc=f"   Processing MADLAD"):
        batch = data[i : i + BATCH_SIZE]
        short_src = [item.get('short_caption_best', "") for item in batch]
        long_src = [item.get('long_caption_best', "") for item in batch]

        short_results.extend(run_gen(short_src, 128)) 
        long_results.extend(run_gen(long_src, 256)) 
        
    return short_results, long_results

# ==========================================
# ä¸»ç¨‹åº
# ==========================================
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--input_file", type=str, required=True)
    parser.add_argument("--output_file", type=str, required=True)
    parser.add_argument("--langs", type=str, required=True, help="é€—å·åˆ†éš”ï¼Œä¾‹å¦‚: uyghur,uzbek")
    parser.add_argument("--gpu_id", type=int, default=0)
    args = parser.parse_args()

    # 1. è§£æè¯­è¨€
    input_langs = [l.strip().lower() for l in args.langs.split(',')]
    valid_langs = []
    for l in input_langs:
        if l in MADLAD_LANG_MAP:
            valid_langs.append(l)
        else:
            print(f"âš ï¸ è­¦å‘Š: è¯­è¨€ '{l}' ä¸åœ¨ MADLAD æ”¯æŒåˆ—è¡¨ä¸­ï¼Œå·²å¿½ç•¥ã€‚")
    
    if not valid_langs:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆçš„è¯­è¨€éœ€è¦ç¿»è¯‘ã€‚")
        return

    device = f"cuda:{args.gpu_id}"
    data = load_data(args.input_file)
    
    # ç»“æœç¼“å­˜ç»“æ„
    results_cache = {lang: {} for lang in valid_langs}

    # ----------------------------------------
    # Loading MADLAD-400
    # ----------------------------------------
    print(f"\n[{device}] Loading MADLAD-400 Model...")
    try:
        m_model = AutoModelForSeq2SeqLM.from_pretrained(MADLAD_PATH, torch_dtype=torch.float16).to(device).eval()
        m_tok = AutoTokenizer.from_pretrained(MADLAD_PATH)
        
        for lang in valid_langs:
            s, l = translate_madlad(m_model, m_tok, data, lang, device)
            results_cache[lang]['short'] = s
            results_cache[lang]['long'] = l
            
        del m_model, m_tok; torch.cuda.empty_cache(); gc.collect()
    except Exception as e:
        print(f"âŒ MADLAD åŠ è½½æˆ–ç¿»è¯‘å¤±è´¥: {e}")
        sys.exit(1)

    # ----------------------------------------
    # åˆå¹¶ä¿å­˜
    # ----------------------------------------
    print(f"\nğŸ”„ æ­£åœ¨å†™å…¥ç»“æœ...")
    for idx, item in enumerate(data):
        if 'translations' not in item: item['translations'] = {}
        
        for lang in valid_langs:
            if lang not in item['translations']:
                item['translations'][lang] = {}
            
            # ä»…å†™å…¥ MADLAD ç»“æœ
            item['translations'][lang]["short_madlad"] = results_cache[lang]['short'][idx]
            item['translations'][lang]["long_madlad"] = results_cache[lang]['long'][idx]

    print(f"ğŸ’¾ ä¿å­˜è‡³: {args.output_file}")
    with open(args.output_file, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    print("ğŸ‰ ç¿»è¯‘å®Œæˆï¼")

if __name__ == "__main__":
    main()