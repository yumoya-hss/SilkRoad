import json
import os

def load_json(file_path):
    """åŠ è½½JSONæ–‡ä»¶ï¼Œå¸¦ç®€å•çš„é”™è¯¯å¤„ç†"""
    if not os.path.exists(file_path):
        print(f"è­¦å‘Š: æ‰¾ä¸åˆ°æ–‡ä»¶ {file_path}")
        return []
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        print(f"è¯»å–é”™è¯¯ {file_path}: {e}")
        return []

def create_lookup_dict(data_list):
    """æ„å»º image_id -> item çš„æ˜ å°„è¡¨ï¼ŒåŠ é€ŸæŸ¥æ‰¾"""
    return {item['image_id']: item for item in data_list}

def merge_scored_datasets():
    # ================= é…ç½®åŒºåŸŸ =================
    # 1. å®šä¹‰æ–‡ä»¶å (å·²æ›´æ–°ä¸ºåŒ…å« QE åˆ†æ•°çš„æ–‡ä»¶)
    main_file = 'dataset_scored_final.json'              # ä¸»æ–‡ä»¶ (é€šå¸¸åŒ…å« NLLB åŠå…¶åˆ†æ•°)
    madlad_file = 'madlad_translation_with_bt_QE.json'   # Madlad å›è¯‘åŠè¯„åˆ†æ–‡ä»¶
    qwen_file = 'qwen_translation_with_bt_QE.json'            # Qwen å›è¯‘åŠè¯„åˆ†æ–‡ä»¶
    
    output_file = 'translated_data_bt_QE.json'           # æœ€ç»ˆåˆå¹¶è¾“å‡ºæ–‡ä»¶
    # ===========================================

    # 2. åŠ è½½æ•°æ®
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ä¸»æ–‡ä»¶: {main_file} ...")
    main_data = load_json(main_file)
    
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ Madlad æ–‡ä»¶: {madlad_file} ...")
    madlad_data = load_json(madlad_file)
    
    print(f"ğŸ“– æ­£åœ¨åŠ è½½ Qwen æ–‡ä»¶: {qwen_file} ...")
    qwen_data = load_json(qwen_file)

    if not main_data:
        print("âŒ ä¸»æ–‡ä»¶åŠ è½½å¤±è´¥æˆ–ä¸ºç©ºï¼Œç¨‹åºç»ˆæ­¢ã€‚")
        return

    # 3. åˆ›å»ºæŸ¥æ‰¾è¡¨ (Hash Map)
    print("âš™ï¸ æ­£åœ¨æ„å»ºç´¢å¼•...")
    madlad_lookup = create_lookup_dict(madlad_data)
    qwen_lookup = create_lookup_dict(qwen_data)

    # 4. å¼€å§‹åˆå¹¶
    print("ğŸ”„ æ­£åœ¨åˆå¹¶ç¿»è¯‘ã€å›è¯‘åŠè¯„åˆ†æ•°æ®...")
    count_updated = 0
    
    for entry in main_data:
        img_id = entry.get('image_id')
        if not img_id:
            continue

        # è·å–å½“å‰æ¡ç›®çš„ç¿»è¯‘å­—å…¸
        current_translations = entry.get('translations', {})

        # --- åˆå¹¶ Madlad æ•°æ® (ç¿»è¯‘+BT+QE) ---
        if img_id in madlad_lookup:
            madlad_entry = madlad_lookup[img_id]
            madlad_trans = madlad_entry.get('translations', {})
            
            for lang, trans_content in madlad_trans.items():
                if lang not in current_translations:
                    current_translations[lang] = {}
                # update ä¼šå°†æ‰€æœ‰æ–°é”®ï¼ˆå¦‚ score_comet_short_madladï¼‰åŠ å…¥å­—å…¸
                current_translations[lang].update(trans_content)

        # --- åˆå¹¶ Qwen æ•°æ® (ç¿»è¯‘+BT+QE) ---
        if img_id in qwen_lookup:
            qwen_entry = qwen_lookup[img_id]
            qwen_trans = qwen_entry.get('translations', {})
            
            for lang, trans_content in qwen_trans.items():
                if lang not in current_translations:
                    current_translations[lang] = {}
                # update ä¼šå°†æ‰€æœ‰æ–°é”®ï¼ˆå¦‚ score_comet_short_qwenï¼‰åŠ å…¥å­—å…¸
                current_translations[lang].update(trans_content)
        
        count_updated += 1

    # 5. ä¿å­˜ç»“æœ
    print(f"âœ… åˆå¹¶å®Œæˆã€‚å…±å¤„ç† {count_updated} æ¡æ•°æ®ã€‚")
    print(f"ğŸ’¾ æ­£åœ¨å†™å…¥æ–‡ä»¶: {output_file}")
    
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(main_data, f, ensure_ascii=False, indent=2)
        print("ğŸ‰ å…¨éƒ¨å®Œæˆï¼")
    except Exception as e:
        print(f"âŒ å†™å…¥å¤±è´¥: {e}")

if __name__ == '__main__':
    merge_scored_datasets()